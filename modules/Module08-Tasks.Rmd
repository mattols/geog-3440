---
title: "Module 8 Assignment"
author: "GEOG-3440"
output: html_document
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(echo = TRUE)
```

Be sure to **read assigned chapters and articles** and carefully walk through all of the **Module Guide** before starting on this task.

*Avoid using packages or solutions beyond the content covered in class or the guide.*

**Submit** your responses in a single, organized html file written in *R Mardown.*

<br />


## **Module Tasks**

Complete the following tasks related to the content of the week. Be sure that each answer is given in an organized, coded solution. All plots should at minimum contain useful axes labels and title.

<br />

*This task will continue working with the UT HUC and SNOTEL datasets to assess the relationships between elevation, location, hydrologic unit, and SWE.*

<br />

#### **Zonal relationships**

Read in the **"UT_HUC8.shp"**. Create a new version of the UT_HUC8 data for HUC6 levels with the `aggregate` function.

Read in the **"UTSNTL_2021_2023_SWE_Joined.csv"** file. This table contains max SWE (*values*) during water years 2021-23 for SNOTEL sites across the state. A join has also been performed with the metadata to include elevation, latitude and longitude. Create a subset of the UTSNTL dataset for the *2022* season and convert this into a `vect` object in `terra` using the Latitude and Longitude coordinates provided.

1. Use the `zonal` function to calculate average SWE (*values*) listed for the 2022 water year in each HUC6 in the state and plot this as interval (default) with 5 classes, using a color scale that varies in shade of blue (*e.g. blues9*). Add HUC6 geometries over the top and run the `zonal` function again (or another tool) to calculate the total number of stations in each HUC6 and add this value with the `text` function in a complementary color (*e.g. red*). Provide a statement about average SWE and the distribution of SNOTEL stations throughout the state.
    * *One option to calculate the count of stations by HUC is to create a new field in your snotel data with the value of 1 and sum these values in the zonal tool.*
   
The Modifiable Areal Unit Problem (MAUP) in geographic analysis refers to the issue that statistical results can change depending on the scale or boundary chosen for aggregating spatial data. This problem occurs when different units of analysis, such as regions or districts, are used, leading to variations in patterns and relationships within the data. MAUP highlights the importance of carefully considering the spatial units and scale when interpreting geographic information.

2. Use the `expanse` function to calculate the area of each HUC6 unit in 10,000s of square kilometers (`unit="km"` and multiply area by `10e3` after). Use this value, along with your zonal statistics output of station counts by HUC6, to create a map that shows the density of stations over the area of each HUC6. How does this change your interpretation of SNOTEL representation within each HUC6?
  
Next, you will obtain a digital elevation model for UT with the `geodata` package and using the following code:

```{r, eval=FALSE}
# install.packages("geodata")
library(geodata)
dem_usa <- elevation_30s("USA", path=tempdir()) # places in a temporary folder for session
dem_usa
```

Create a subset of the the dem above for the state of Utah using the `crop` function and the UT HUC6 data as the extent object (`y`), add the `mask=TRUE` argument to mask the feature to the shape of the extent of the HUC6 feature, which is the state boundary (*don't forget to keep track of the crs of your datasets*).

3. Convert your UT dem from meters of elevation to feet with simple arithmetic (*1 meter = 3.281 feet*) and use the elevation range for all SNOTEL sites to create a new dem (*dem_snotel*) that only shows cell values that are within the same range as SNOTEL sites state-wide. This can be accomplished with indexing and boolean logic, or the `clamp` function. Plot your subset elevation raster with the HUC6 borders overlapping. 

4. Use both the UT DEM and your masked `dem_snotel` rasters to calculate the percentage (rounded to the nearest whole number) of pixels within the range of SNOTEL elevations by HUC6. To do this, use the `!is.na` function on the raster to create a binary raster. Then, use the `zonal` function to sum the number of pixels by HUC6 in each raster. Plot the percentages for each HUC6 with the default 5 interval classification (use a sequential color palette like `heat.colors` or similar to emphasize higher values), then add `text` values over the top that show the percentage followed by the "%" for each HUC6.
    * *Tip: add new columns to your HUC6 vector using the output from zonal statistics that show the count of pixels. Add another column using the* `paste` *function to combine numbers and characters for the text*.

Let's assess the elevation values reported in our SNOTEL data with the raster dataset we downloaded. Let's consider the elevation reported at the SNOTEL station to be the actual *observed* value, and the dem elevation as our *predicted* value.

Root Mean Squared Error (RMSE) is a measure of the differences between predicted and observed values in a model. It represents the square root of the average squared differences between the predicted and actual values, providing an indication of how well the model fits the data. The formula for RMSE is:

$$
RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}
$$

where \(y_i\) is the observed value, \(\hat{y}_i\) is the predicted value, and \(n\) is the number of data points. \(y_i - \hat{y}_i\) is also the residual from the `lm` output.

RMSE shows how well a model's predictions match the actual values, with lower values indicating a better fit. The key point in interpreting RMSE is that it is expressed in the same units as the data, so its magnitude is directly tied to the scale of the variable being predicted (*e.g. if predicting temperature in degrees Celsius, the RMSE will be in degrees Celsius*). A smaller RMSE means the predictions are closer to the true values, while a larger RMSE suggests greater errors. The acceptable value for RMSE depends on the context—what’s considered a "good" RMSE can vary depending on the specific problem and the scale of the data.

5. Use the `extract` function to extract the raster UT dem elevation values (`x`) at each snotel site (`y`) in your vector point data (*note, the dimensions should match your snotel data, which can be added as a new column*). Use these values to create a scatterplot that shows predicted values (x-axis) with observed values. Add a 1:1 line using the `abline` function (*a perfect match would show the all points on the 1:1 line*). Add the RMSE (rounded to whole number) as text in the topright corner of the plot.

<br />

#### **Relationships between snow and elevation**

Now let's change gears and return to an analysis of snow water equivalent and elevation. It is well known that precipitation amount can be enhanced at higher elevations due to orographic lift (air masses flowing over mountains). Utah's mountains benefit and often have an enhancement of 2-7 (or more) times the amount of precipitation.

6. Using either base R or ggplot, create a scatter plot with the SNOTEL data that shows the max SWE (snow water equivalent) during the 2022 winter season as a function of elevation (x-axis). Add a linear model using `geom_smooth` *(ggplot)* or `lm` and `abline` *(base)* alongside the point data to visualize any linear relationship that might exist.

7. Statistically assess the strength of the linear relationship between max SWE as a function of elevation with `lm`. Consider the direction, strength, significance, and wellness of fit of this relationship, and discuss whether elevation is a good predictor of SWE.

Interesting, but we are spatial thinkers. Let's include some of the spatial information available into our analysis.

Multiple linear regression is a statistical technique used to model the relationship between two or more predictor variables and a continuous outcome variable. It is useful for understanding how several factors simultaneously influence an outcome, helping to make predictions and identify important variables.

The equation below shows how to perform multiple linear regression in R:

```r
fit <- lm(y ~ x1 + x2 + x3 + ..., data = dataset)
```

8. Perform multiple linear regression using elevation, latitude, and longitude all as independent variables that relate to SWE. How does this model compare with your model in the previous question? Be specific and describe why one of these might be a better way to model SWE over the other.

We can move beyond incorporating spatial coordinates in our analysis. Spatial data science involves geographic data manipulation to improve analysis. Use either the `intersect` or `extract` function in `terra` to obtain the HUC6 code for each SNOTEL station. The result should be either a dataframe vector model of the same length as snotel sites. The HUC6 label can be used as a regional indicator to separate our linear. Filter out any HUC6 zones that contain less than 8 snotel stations (*i.e. remove all points from these HUCs in your final analysis below*). **This should only leave you with a total of six HUC6 regions.**

9. (*2 pts*) Investigate the affect of elevation on max seasonal SWE (*inches*) by HUC6 code. Provide a scatterplot and linear model showing the relationship and report, the significance (*p-value*) and either the wellness of fit (\R^2\) or the RMSE for each. Finally, use the Estimate (for *elevation_ft*) to describe how SWE changes relative to an increase of 1,000 feet within each of the six HUC6 regions.
    * *The estimate (also known as the regression coefficient) represents the expected change in the outcome variable (dependent variable) for a one-unit change in the predictor variable (independent variable), while holding all other predictors constant. In other words, this value will descibes how a 1 unit change in x impacts a 1 unit change in 7*

**Tips:** *you may use base R but these steps are much faster and efficient using additional packages*:

* `group_by` and `summarize` data with `dplyr`, where you will group by the HUC units
* the `n()` function can count occurences in the `summarize` table
* the `%in%` function, along with `filter` could quickly remove unwanted rows (HUC6s)
* `ggplot` has the `facet_wrap` functions to create multiple scatterplots side-by-side
* the `tidyverse` and `broom` packages have great ways of running multiple linear models for grouped variables



<br />

#### Submitting

Upload a single, organized **html file** written in **R Markdown** showing **questions, code solutions, and responses**. Be sure to support your responses with code and result outputs.

*Please reach out if you have any questions or concerns!*

<br />
<br />

